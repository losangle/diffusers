{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRJ29SnKa8VA"
      },
      "source": [
        "Log into HuggingFace to utilize their stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_hAFJjda5vY"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqifMJMWB_3D"
      },
      "source": [
        "Install Diffusers (https://github.com/huggingface/diffusers/tree/main)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8FOMrznZec2"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/losangle/diffusers.git\n",
        "%cd diffusers\n",
        "!git branch\n",
        "!pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJRN5bztYZE0"
      },
      "source": [
        "Install requirements for Textual Inversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOTgHxb7733O"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate>=0.16.0\n",
        "!pip install torchvision\n",
        "!pip install transformers>=4.25.1\n",
        "!pip install ftfy\n",
        "!pip install tensorboard\n",
        "!pip install Jinja2\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr0xdK7wYgfJ"
      },
      "source": [
        "Get into correct directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3IMxzr5Phcb"
      },
      "outputs": [],
      "source": [
        "%cd ./examples/textual_inversion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xURx-iD7XMoi"
      },
      "source": [
        "Download Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWMDXK9WXMoi"
      },
      "outputs": [],
      "source": [
        "!wget https://isic-challenge-data.s3.amazonaws.com/2020/ISIC_2020_Training_JPEG.zip\n",
        "!unzip ./ISIC_2020_Training_JPEG.zip\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1bKdhh7eAjZVWVDl5eH5gQdoZwNlgVS2C' -O ./ISIC_2020_Training_GroundTruth.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewQIiwOsXMoi"
      },
      "source": [
        "Select which images to train on and generate differently sampled training datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RolevGanXMoi"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def extract_image_data():\n",
        "    images = []\n",
        "    first = True\n",
        "    with open('ISIC_2020_Training_GroundTruth.csv') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        for row in reader:\n",
        "          if (first):\n",
        "            first = False\n",
        "          else:\n",
        "            images.append({\n",
        "                'name': row[0],\n",
        "                'sex': row[2],\n",
        "                'age': float(row[3]) if row[3] != '' else -1,\n",
        "                'race': row[9],\n",
        "                'cancer_status': row[6]\n",
        "            })\n",
        "    return images\n",
        "\n",
        "def sample_images(images, output_dir, num_images, criteria):\n",
        "    categories = ['sex', 'race', 'cancer_status']\n",
        "    categories = [c for c in categories if criteria[c] != 'ANY'] # ignore the 'ANY' criteria\n",
        "\n",
        "    passing_images = []\n",
        "    for image in images:\n",
        "        pass_criteria = all([criteria[n] == image[n] for n in categories])\n",
        "        pass_criteria = pass_criteria and (criteria['age_lower'] <= image['age'] <= criteria['age_upper'])\n",
        "        if (pass_criteria): passing_images.append(image['name'])\n",
        "\n",
        "    image_samples = np.random.choice(passing_images, size=min(len(passing_images), num_images), replace=False)\n",
        "\n",
        "    os.system(f'rm -rf {output_dir}') # make sure it is empty if we run this multiple times\n",
        "    os.mkdir(output_dir)\n",
        "\n",
        "    for image_sample in image_samples:\n",
        "        source_path = os.path.join(os.getcwd(), 'train', f'{image_sample}.jpg')\n",
        "        dst_path = os.path.join(os.getcwd(), output_dir, f'{image_sample}.jpg')\n",
        "        os.system(f'cp {source_path} {dst_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample from entire dataset to create training datasets"
      ],
      "metadata": {
        "id": "WJayRiig0rzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = extract_image_data()\n",
        "\n",
        "# sex : male / female\n",
        "# race : very_lt / lt2 / lt1 / int2 / int1 / tan2 / tan1 / Dark (lt = light, so very_lt =  very light and lt2 = light 2, int = intermediate, so int1 = intermediate 1)\n",
        "# cancer_status : malignant / benign\n",
        "\n",
        "criteria = {\n",
        "    'sex': 'ANY',\n",
        "    'race': 'dark',\n",
        "    'cancer_status': 'malignant',\n",
        "    'age_lower': 0,\n",
        "    'age_upper': 100\n",
        "}\n",
        "\n",
        "sample_images(images, './malignant_dataset', 15, criteria)\n",
        "\n",
        "criteria = {\n",
        "    'sex': 'ANY',\n",
        "    'race': 'dark',\n",
        "    'cancer_status': 'benign',\n",
        "    'age_lower': 0,\n",
        "    'age_upper': 100\n",
        "}\n",
        "sample_images(images, './benign_dataset', 15, criteria)\n",
        "\n",
        "!ls benign_dataset\n",
        "!ls malignant_dataset"
      ],
      "metadata": {
        "id": "QMzo_lre0vCb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d62ef86-c472-497e-8cbd-d17ff6462462"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "33127it [00:00, 267109.42it/s]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': 'ISIC_2637011', 'sex': 'male', 'age': 45.0, 'race': 'very_lt', 'cancer_status': 'benign'}, {'name': 'ISIC_0015719', 'sex': 'female', 'age': 45.0, 'race': 'lt1', 'cancer_status': 'benign'}, {'name': 'ISIC_0052212', 'sex': 'female', 'age': 50.0, 'race': 'very_lt', 'cancer_status': 'benign'}, {'name': 'ISIC_0068279', 'sex': 'female', 'age': 45.0, 'race': 'dark', 'cancer_status': 'benign'}, {'name': 'ISIC_0074268', 'sex': 'female', 'age': 55.0, 'race': 'very_lt', 'cancer_status': 'benign'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete entire dataset to conserve disk space"
      ],
      "metadata": {
        "id": "N6C5DJWy0vsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.system(f'rm -rf {os.path.join(os.getcwd(), \"train\")}')\n",
        "os.system(f'rm -rf {os.path.join(os.getcwd(), \"ISIC_2020_Training_JPEG.zip\")}')\n",
        "!ls"
      ],
      "metadata": {
        "id": "zj4rRCgV0yh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-ZokbCgCMlC"
      },
      "source": [
        "Import what's neccessary (just textual inversion stuff for now)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wf6XKXcVaKG2"
      },
      "outputs": [],
      "source": [
        "from accelerate.utils import write_basic_config\n",
        "write_basic_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRhEx7pkXMoj"
      },
      "source": [
        "Run Textual Inversion Pipeline. Adjust the parameters as desired based off of the training dataset used and run as many times as desired"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0G--IS8D-Ouq"
      },
      "outputs": [],
      "source": [
        "!accelerate launch textual_inversion.py \\\n",
        "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
        "  --train_data_dir=\"./malignant_dataset\" \\\n",
        "  --learnable_property=\"style\" \\\n",
        "  --placeholder_token=\"<malignant>\" \\\n",
        "  --initializer_token=\"melanoma\" \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --max_train_steps=1 \\\n",
        "  --learning_rate=5.0e-04 \\\n",
        "  --scale_lr \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --output_dir=\"textual_inversion_melanoma\" \\\n",
        "  --push_to_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36tWwb4YXMoj"
      },
      "source": [
        "Use learned embeddings to generate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlMcxepbXMoj"
      },
      "outputs": [],
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "def generate_images(embedding_dir, num_images, output_dir, generation_string):\n",
        "    pipeline = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16).to(\"cuda\")\n",
        "    pipeline.load_textual_inversion(embedding_dir)\n",
        "\n",
        "    os.system(f'rm -rf {output_dir}')\n",
        "    os.mkdir(output_dir)\n",
        "\n",
        "    while (num_images > 0):\n",
        "        images = pipeline(generation_string, num_inference_steps=50).images\n",
        "        for image in images:\n",
        "            image.save(os.path.join(output_dir, f'{num_images}.png'))\n",
        "            num_images -= 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate images"
      ],
      "metadata": {
        "id": "zojkbrEsPFcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_images('./textual_inversion_melanoma', 10, './images_out', \"melanoma <malignant>\")"
      ],
      "metadata": {
        "id": "da1tEAndPHK-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}